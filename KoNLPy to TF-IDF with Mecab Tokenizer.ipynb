{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶œì²˜: https://blog.breezymind.com/2018/03/02/sklearn-feature_extraction-text-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(0)\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "# tokenizer : ë¬¸ì¥ì—ì„œ ìƒ‰ì¸ì–´ ì¶”ì¶œì„ ìœ„í•´ ëª…ì‚¬,ë™ì‚¬,ì•ŒíŒŒë²³,ìˆ«ì ì •ë„ì˜ ë‹¨ì–´ë§Œ ë½‘ì•„ì„œ normalization, stemming ì²˜ë¦¬í•˜ë„ë¡ í•¨\n",
    "def tokenizer(raw, pos=[\"NNG\",\"NNP\"], stopword=['ìˆ˜','í€„ë¦¬í‹°','ë„ì‹œ','ë¶„','ì „ë¬¸','ìŠ¤íƒ€','ë…„','ì›',\\\n",
    "                       'ì›”','í™”','ìˆ˜','ëª©','ê¸ˆ','ì‹œ','ì•¤','ì¼','ê·¸ë¨','ë¬¸'] ):\n",
    "    return [\n",
    "        word for word, tag in mecab.pos(raw)\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥\n",
    "df = pd.read_csv(\"word2vec_wrangling.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise_name</th>\n",
       "      <th>Content_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PT</td>\n",
       "      <td>ğŸ’¯ What I try to educate my clients around, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ê²€ë„</td>\n",
       "      <td>#20200115\\nì €ë… ì´ˆëŒ€!\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\në„ì‹¬ì†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ê¸°êµ¬í•„ë¼í…ŒìŠ¤</td>\n",
       "      <td>#ì˜¤ëŠ˜ì˜ë™ì‘\\nìºë”œë½ ë™ì‘ì˜ ì™„ì„± 'í–‰ì‰'\\nâ €\\nì¤‘ë ¥ì„ ì´ìš©í•´ ì²™ì¶”ë¥¼ ëŠ˜ë ¤ì£¼ê³ \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ</td>\n",
       "      <td>#mbnìƒìƒì •ë³´ë§ˆë‹¹ \\n#ê³ íˆ¬\\n#ê³ íˆ¬GX\\n#ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ\\n#ìƒë°©ì†¡ #GOTOL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ë“œëŸ¼ìŠ¤í‹±</td>\n",
       "      <td>#ë“œëŸ¼ìŠ¤í‹± #ê³ ë¬´íŒ #í…Œí¬ë¼ìŠ¤í‹± #ì „ìë“œëŸ¼ìš©ìŠ¤í‹±\\n\\n1. ì „ìë“œëŸ¼íƒ€ê²©ì‹œ ëœ ì‹œë„ëŸ½...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  exercise_name                                        Content_txt\n",
       "0            PT  ğŸ’¯ What I try to educate my clients around, doe...\n",
       "1            ê²€ë„  #20200115\\nì €ë… ì´ˆëŒ€!\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\në„ì‹¬ì†...\n",
       "2        ê¸°êµ¬í•„ë¼í…ŒìŠ¤  #ì˜¤ëŠ˜ì˜ë™ì‘\\nìºë”œë½ ë™ì‘ì˜ ì™„ì„± 'í–‰ì‰'\\nâ €\\nì¤‘ë ¥ì„ ì´ìš©í•´ ì²™ì¶”ë¥¼ ëŠ˜ë ¤ì£¼ê³ \\n...\n",
       "3       ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ  #mbnìƒìƒì •ë³´ë§ˆë‹¹ \\n#ê³ íˆ¬\\n#ê³ íˆ¬GX\\n#ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ\\n#ìƒë°©ì†¡ #GOTOL...\n",
       "4          ë“œëŸ¼ìŠ¤í‹±  #ë“œëŸ¼ìŠ¤í‹± #ê³ ë¬´íŒ #í…Œí¬ë¼ìŠ¤í‹± #ì „ìë“œëŸ¼ìš©ìŠ¤í‹±\\n\\n1. ì „ìë“œëŸ¼íƒ€ê²©ì‹œ ëœ ì‹œë„ëŸ½..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessing(text):\n",
    "    # ê°œí–‰ë¬¸ì ì œê±°\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    # íŠ¹ìˆ˜ë¬¸ìë‚˜ ì´ëª¨í‹°ì½˜ ë“±ì€ ë•Œë¡œëŠ” ì˜ë¯¸ë¥¼ ê°–ê¸°ë„ í•˜ì§€ë§Œ ì—¬ê¸°ì—ì„œëŠ” ì œê±°í–ˆìŠµë‹ˆë‹¤.\n",
    "    # text = re.sub('[?.,;:|\\)*~`â€™!^\\-_+<>@\\#$%&-=#}â€»]', '', text)\n",
    "    # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    # text = re.sub('[^ê°€-í£ã„±-ã…ã…-ã…£a-zA-Z0-9]', ' ', text)\n",
    "    # í•œê¸€, ì˜ë¬¸ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    text = re.sub('[^ê°€-í£ã„±-ã…ã…-ã…£a-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 7.03 ms, total: 1.06 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%time rawdata = df['Content_txt'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.02304771 0.         ... 0.         0.         0.        ]\n",
      " [0.00731699 0.00520238 0.         ... 0.         0.         0.01417282]\n",
      " [0.01754004 0.01806715 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.01625052 0.02232546 0.         ... 0.01161061 0.         0.        ]\n",
      " [0.01834636 0.0212857  0.         ... 0.         0.         0.        ]\n",
      " [0.         0.02156329 0.         ... 0.         0.         0.07388052]]\n"
     ]
    }
   ],
   "source": [
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer,\n",
    "    min_df=5,\n",
    "    sublinear_tf=True    # tfê°’ì— 1+log(tf)ë¥¼ ì ìš©í•˜ì—¬ tfê°’ì´ ë¬´í•œì • ì»¤ì§€ëŠ” ê²ƒì„ ë§‰ìŒ\n",
    ")\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "\n",
    "# fit_transform, (sentence 5, feature 7)\n",
    "\n",
    "print(X.toarray())\n",
    "\n",
    "# ([[0.        , 0.40824829, 0.81649658, 0.        , 0.        , 0.        , 0.40824829],\n",
    "# [0.        , 0.40824829, 0.40824829, 0.        , 0.        , 0.        , 0.81649658],\n",
    "# [0.41680418, 0.        , 0.        , 0.69197025, 0.41680418, 0.41680418, 0.        ],\n",
    "# [0.76944707, 0.        , 0.        , 0.63871058, 0.        , 0.        , 0.        ],\n",
    "# [0.        , 0.        , 0.        , 0.8695635 , 0.34918428, 0.34918428, 0.        ]])\n",
    "\n",
    "# ë¬¸ì¥ì—ì„œ ë½‘ì•„ë‚¸ feature ë“¤ì˜ ë°°ì—´\n",
    "features = vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9661\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ê°€ê²Œ', 'ê°€ê²©', 'ê°€ê²½ë™', 'ê°€ê³µ', 'ê°€êµ¬', 'ê°€ê¸ˆ', 'ê°€ê¹Œì´', 'ê°€ë„¤ìƒ¤', 'ê°€ëŠ ', 'ê°€ëŠ¥', 'ê°€ë™', 'ê°€ë“œ']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ë³µê·¼', 'ìš´ë™']\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰ ë¬¸ì¥ì—ì„œ featureë¥¼ ë½‘ì•„ëƒ„\n",
    "srch=[t for t in tokenizer('ë³µê·¼ì´ ìƒê¸°ëŠ” ìš´ë™') if t in features]\n",
    "print(srch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03629959, 0.06352614],\n",
       "       [0.00583699, 0.0338335 ],\n",
       "       [0.02324348, 0.03261501],\n",
       "       [0.01850878, 0.03615956],\n",
       "       [0.        , 0.02087139],\n",
       "       [0.00598205, 0.03129328],\n",
       "       [0.        , 0.03310441],\n",
       "       [0.02149545, 0.03386523],\n",
       "       [0.02270879, 0.03693905],\n",
       "       [0.        , 0.03386949],\n",
       "       [0.01263085, 0.02884251],\n",
       "       [0.01572474, 0.03272411],\n",
       "       [0.01535327, 0.02905333],\n",
       "       [0.        , 0.03782721],\n",
       "       [0.01235037, 0.03787701],\n",
       "       [0.02095056, 0.03649797],\n",
       "       [0.019482  , 0.03464524],\n",
       "       [0.        , 0.02868688],\n",
       "       [0.00859096, 0.0286425 ],\n",
       "       [0.01559038, 0.03315197],\n",
       "       [0.        , 0.03190364],\n",
       "       [0.        , 0.02639931],\n",
       "       [0.01929779, 0.03356973],\n",
       "       [0.01036368, 0.02669378],\n",
       "       [0.01554211, 0.03055554],\n",
       "       [0.02038296, 0.0312415 ],\n",
       "       [0.00487456, 0.02702579],\n",
       "       [0.01301678, 0.03419773],\n",
       "       [0.02120869, 0.06090998],\n",
       "       [0.        , 0.08576145],\n",
       "       [0.01856148, 0.04073216],\n",
       "       [0.01751958, 0.03437352],\n",
       "       [0.        , 0.12866966],\n",
       "       [0.01751699, 0.02944451],\n",
       "       [0.        , 0.06013438],\n",
       "       [0.        , 0.02191491],\n",
       "       [0.01358522, 0.03580685],\n",
       "       [0.        , 0.03561605],\n",
       "       [0.02420903, 0.03678014],\n",
       "       [0.01421399, 0.03647141],\n",
       "       [0.01453377, 0.03087687],\n",
       "       [0.02331743, 0.03868304],\n",
       "       [0.02069084, 0.03599498],\n",
       "       [0.0193063 , 0.03733186],\n",
       "       [0.02602734, 0.03658623],\n",
       "       [0.00578384, 0.02088416],\n",
       "       [0.01430719, 0.03180214],\n",
       "       [0.01782563, 0.04300799],\n",
       "       [0.00558333, 0.03027471],\n",
       "       [0.        , 0.12235442],\n",
       "       [0.        , 0.03965288],\n",
       "       [0.02722751, 0.03742276],\n",
       "       [0.01438898, 0.03362414],\n",
       "       [0.01971143, 0.0317575 ],\n",
       "       [0.02799745, 0.04058869],\n",
       "       [0.        , 0.10583776],\n",
       "       [0.02424595, 0.03988528],\n",
       "       [0.00470812, 0.02318421],\n",
       "       [0.01600366, 0.03243396],\n",
       "       [0.02521939, 0.03597101],\n",
       "       [0.00821263, 0.04612304]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtm ì—ì„œ ê²€ìƒ‰í•˜ê³ ì í•˜ëŠ” featureë§Œ ë½‘ì•„ë‚¸ë‹¤.\n",
    "srch_dtm = np.asarray(X.toarray())[:, [\n",
    "    # vectorize.vocabulary_.get ëŠ” íŠ¹ì • feature ê°€ dtm ì—ì„œ ê°€ì§€ê³  ìˆëŠ” indexê°’ì„ ë¦¬í„´í•œë‹¤\n",
    "    vectorize.vocabulary_.get(i) for i in srch\n",
    "]]\n",
    "\n",
    "print(len(srch_dtm))\n",
    "srch_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09982573, 0.0396705 , 0.05585849, 0.05466834, 0.02087139,\n",
       "       0.03727532, 0.03310441, 0.05536068, 0.05964784, 0.03386949,\n",
       "       0.04147337, 0.04844884, 0.04440661, 0.03782721, 0.05022738,\n",
       "       0.05744853, 0.05412724, 0.02868688, 0.03723346, 0.04874235,\n",
       "       0.03190364, 0.02639931, 0.05286752, 0.03705746, 0.04609764,\n",
       "       0.05162445, 0.03190035, 0.04721451, 0.08211868, 0.08576145,\n",
       "       0.05929364, 0.0518931 , 0.12866966, 0.0469615 , 0.06013438,\n",
       "       0.02191491, 0.04939207, 0.03561605, 0.06098917, 0.05068541,\n",
       "       0.04541064, 0.06200047, 0.05668582, 0.05663816, 0.06261358,\n",
       "       0.026668  , 0.04610933, 0.06083362, 0.03585804, 0.12235442,\n",
       "       0.03965288, 0.06465027, 0.04801312, 0.05146894, 0.06858613,\n",
       "       0.10583776, 0.06413124, 0.02789233, 0.04843761, 0.0611904 ,\n",
       "       0.05433567])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = srch_dtm.sum(axis=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ì—ì´ë¦¬ì–¼í›„í”„', 0.12866966339086583)\n",
      "('íŒ¨ë“¤í•', 0.12235441995412155)\n",
      "('í•„ë¼í…ŒìŠ¤', 0.10583776104833163)\n",
      "('PT', 0.09982573437229232)\n",
      "('ì•„ì¿ ì•„í…Œí¬', 0.08576145092896134)\n",
      "('ì•„ì¿ ì•„ë°”ì´í¬', 0.08211867738708024)\n",
      "('í”Œë¼ì‰í•„ë¼í…ŒìŠ¤', 0.06858613060515403)\n"
     ]
    }
   ],
   "source": [
    "for i in score.argsort()[::-1]:\n",
    "    if score[i] > 0.065:\n",
    "        print((df['exercise_name'].iloc[i], score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
