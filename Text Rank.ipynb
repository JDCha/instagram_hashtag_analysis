{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ì¶œì²˜: https://excelsior-cjh.tistory.com/93 [EXCELSIOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Mecab()\n",
    "        self.twitter = Okt()\n",
    "        self.stopwords = ['ì¤‘ì¸' ,'ë§Œí¼', 'ë§ˆì°¬ê°€ì§€', 'ê¼¬ì§‘ì—ˆ', \"ì—°í•©ë‰´ìŠ¤\", \"ë°ì¼ë¦¬\", \"ë™ì•„ì¼ë³´\", \"ì¤‘ì•™ì¼ë³´\", \"ì¡°ì„ ì¼ë³´\", \"ê¸°ì\"\n",
    "             ,\"ì•„\", \"íœ´\", \"ì•„ì´êµ¬\", \"ì•„ì´ì¿ \", \"ì•„ì´ê³ \", \"ì–´\", \"ë‚˜\", \"ìš°ë¦¬\", \"ì €í¬\", \"ë”°ë¼\", \"ì˜í•´\", \"ì„\", \"ë¥¼\", \"ì—\", \"ì˜\", \"ê°€\",]\n",
    "\n",
    "    def url2sentences(self, url):\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        sentences = self.kkma.sentences(article.text)\n",
    "        \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        \n",
    "        return sentences\n",
    "    \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)      \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        \n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                nouns.append(' '.join([noun for noun in self.twitter.nouns(str(sentence)) \n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        \n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "        \n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return  self.graph_sentence\n",
    "        \n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal ë¶€ë¶„ì„ 0ìœ¼ë¡œ \n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "            \n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # ì—°ë¦½ë°©ì •ì‹ Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        \n",
    "        self.sentences = self.sent_tokenize\n",
    "        \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "                    \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "        \n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "        \n",
    "        self.word_rank_idx =  self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "        \n",
    "        \n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "        \n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "        \n",
    "        return summary\n",
    "        \n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "        \n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "            \n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        \n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(0)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥\n",
    "df = pd.read_csv(\"word2vec_wrangling.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise_name</th>\n",
       "      <th>Content_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PT</td>\n",
       "      <td>ğŸ’¯ What I try to educate my clients around, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ê²€ë„</td>\n",
       "      <td>#20200115\\nì €ë… ì´ˆëŒ€!\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\në„ì‹¬ì†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ê¸°êµ¬í•„ë¼í…ŒìŠ¤</td>\n",
       "      <td>#ì˜¤ëŠ˜ì˜ë™ì‘\\nìºë”œë½ ë™ì‘ì˜ ì™„ì„± 'í–‰ì‰'\\nâ €\\nì¤‘ë ¥ì„ ì´ìš©í•´ ì²™ì¶”ë¥¼ ëŠ˜ë ¤ì£¼ê³ \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ</td>\n",
       "      <td>#mbnìƒìƒì •ë³´ë§ˆë‹¹ \\n#ê³ íˆ¬\\n#ê³ íˆ¬GX\\n#ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ\\n#ìƒë°©ì†¡ #GOTOL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ë“œëŸ¼ìŠ¤í‹±</td>\n",
       "      <td>#ë“œëŸ¼ìŠ¤í‹± #ê³ ë¬´íŒ #í…Œí¬ë¼ìŠ¤í‹± #ì „ìë“œëŸ¼ìš©ìŠ¤í‹±\\n\\n1. ì „ìë“œëŸ¼íƒ€ê²©ì‹œ ëœ ì‹œë„ëŸ½...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  exercise_name                                        Content_txt\n",
       "0            PT  ğŸ’¯ What I try to educate my clients around, doe...\n",
       "1            ê²€ë„  #20200115\\nì €ë… ì´ˆëŒ€!\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\në„ì‹¬ì†...\n",
       "2        ê¸°êµ¬í•„ë¼í…ŒìŠ¤  #ì˜¤ëŠ˜ì˜ë™ì‘\\nìºë”œë½ ë™ì‘ì˜ ì™„ì„± 'í–‰ì‰'\\nâ €\\nì¤‘ë ¥ì„ ì´ìš©í•´ ì²™ì¶”ë¥¼ ëŠ˜ë ¤ì£¼ê³ \\n...\n",
       "3       ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ  #mbnìƒìƒì •ë³´ë§ˆë‹¹ \\n#ê³ íˆ¬\\n#ê³ íˆ¬GX\\n#ë‹¤ë¹ˆì¹˜ë°”ë””ë³´ë“œ\\n#ìƒë°©ì†¡ #GOTOL...\n",
       "4          ë“œëŸ¼ìŠ¤í‹±  #ë“œëŸ¼ìŠ¤í‹± #ê³ ë¬´íŒ #í…Œí¬ë¼ìŠ¤í‹± #ì „ìë“œëŸ¼ìš©ìŠ¤í‹±\\n\\n1. ì „ìë“œëŸ¼íƒ€ê²©ì‹œ ëœ ì‹œë„ëŸ½..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(exercise_name):\n",
    "    row_index_number = df.loc[df['exercise_name']==exercise_name].index\n",
    "    series = df[\"Content_txt\"].iloc[row_index_number]\n",
    "    print(series)\n",
    "    text = series.to_string(index=False)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    #20200115\\nì €ë… ì´ˆëŒ€!\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\në„ì‹¬ì†...\n",
      "Name: Content_txt, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(\"ê²€ë„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#20200115\\nì €ë… ì´ˆëŒ€!\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\në„ì‹¬ì†.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "summarize() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-3c8017eb0e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtextrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#20200115\\\\nì €ë… ì´ˆëŒ€!\\\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\\\në„ì‹¬ì†...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextrank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextrank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# up to 3 sentences, returned as list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: summarize() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "from textrankr import TextRank\n",
    "textrank = TextRank(\"#20200115\\\\nì €ë… ì´ˆëŒ€!\\\\nì™€ì¸ì” ì†ì— ë¹„ì¹˜ëŠ”\\\\nëª¨ë“  ê²ƒë“¤ì´ í™”ë ¤í•œ\\\\në„ì‹¬ì†...\")\n",
    "print(textrank.summarize())\n",
    "print(textrank.summarize(3, verbose=False))  # up to 3 sentences, returned as list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
