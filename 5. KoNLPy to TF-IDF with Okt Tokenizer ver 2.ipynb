{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처: https://blog.breezymind.com/2018/03/02/sklearn-feature_extraction-text-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(0)\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "twitter = Okt()\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "# tokenizer : 문장에서 색인어 추출을 위해 명사,동사,알파벳,숫자 정도의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "# tokenizer : 문장에서 색인어 추출을 위해 명사,동사,알파벳,숫자 정도의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "def tokenizer(raw, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stopword=[]):\n",
    "    return [\n",
    "        word for word, tag in twitter.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]\n",
    "\n",
    "# 테스트 문장\n",
    "df = pd.read_csv(\"word2vec_wrangling.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise_name</th>\n",
       "      <th>Content_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PT</td>\n",
       "      <td>💯 What I try to educate my clients around, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>검도</td>\n",
       "      <td>#20200115\\n저녁 초대!\\n와인잔 속에 비치는\\n모든 것들이 화려한\\n도심속...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>기구필라테스</td>\n",
       "      <td>#오늘의동작\\n캐딜락 동작의 완성 '행잉'\\n⠀\\n중력을 이용해 척추를 늘려주고\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>다빈치바디보드</td>\n",
       "      <td>#mbn생생정보마당 \\n#고투\\n#고투GX\\n#다빈치바디보드\\n#생방송 #GOTOL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>드럼스틱</td>\n",
       "      <td>#드럼스틱 #고무팁 #테크라스틱 #전자드럼용스틱\\n\\n1. 전자드럼타격시 덜 시끄럽...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  exercise_name                                        Content_txt\n",
       "0            PT  💯 What I try to educate my clients around, doe...\n",
       "1            검도  #20200115\\n저녁 초대!\\n와인잔 속에 비치는\\n모든 것들이 화려한\\n도심속...\n",
       "2        기구필라테스  #오늘의동작\\n캐딜락 동작의 완성 '행잉'\\n⠀\\n중력을 이용해 척추를 늘려주고\\n...\n",
       "3       다빈치바디보드  #mbn생생정보마당 \\n#고투\\n#고투GX\\n#다빈치바디보드\\n#생방송 #GOTOL...\n",
       "4          드럼스틱  #드럼스틱 #고무팁 #테크라스틱 #전자드럼용스틱\\n\\n1. 전자드럼타격시 덜 시끄럽..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessing(text):\n",
    "    # 개행문자 제거\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    # 특수문자 제거\n",
    "    # 특수문자나 이모티콘 등은 때로는 의미를 갖기도 하지만 여기에서는 제거했습니다.\n",
    "    # text = re.sub('[?.,;:|\\)*~`’!^\\-_+<>@\\#$%&-=#}※]', '', text)\n",
    "    # 한글, 영문, 숫자만 남기고 모두 제거하도록 합니다.\n",
    "    # text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', ' ', text)\n",
    "    # 한글, 영문만 남기고 모두 제거하도록 합니다.\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 985 ms, sys: 19.6 ms, total: 1 s\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%time rawdata = df['Content_txt'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01845768 0.         0.00949002 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.01298815 0.        ]\n",
      " [0.         0.02342017 0.         ... 0.01069141 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01089691 0.         0.02467502 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.06379826 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer,\n",
    "    min_df=5,\n",
    "    sublinear_tf=True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "\n",
    "# fit_transform, (sentence 5, feature 7)\n",
    "\n",
    "print(X.toarray())\n",
    "\n",
    "# ([[0.        , 0.40824829, 0.81649658, 0.        , 0.        , 0.        , 0.40824829],\n",
    "# [0.        , 0.40824829, 0.40824829, 0.        , 0.        , 0.        , 0.81649658],\n",
    "# [0.41680418, 0.        , 0.        , 0.69197025, 0.41680418, 0.41680418, 0.        ],\n",
    "# [0.76944707, 0.        , 0.        , 0.63871058, 0.        , 0.        , 0.        ],\n",
    "# [0.        , 0.        , 0.        , 0.8695635 , 0.34918428, 0.34918428, 0.        ]])\n",
    "\n",
    "# 문장에서 뽑아낸 feature 들의 배열\n",
    "features = vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14098\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'abc',\n",
       " 'abdominal',\n",
       " 'able',\n",
       " 'about',\n",
       " 'abs',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'account',\n",
       " 'ace',\n",
       " 'acrobatics']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['복근', '생기다', '운동']\n"
     ]
    }
   ],
   "source": [
    "# 검색 문장에서 feature를 뽑아냄\n",
    "srch=[t for t in tokenizer('복근이 생기는 운동') if t in features]\n",
    "print(srch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01171391, 0.00792608, 0.02049993],\n",
       "       [0.00513336, 0.01197104, 0.02970128],\n",
       "       [0.02089141, 0.01434384, 0.02915134],\n",
       "       [0.01628533, 0.01316946, 0.03158734],\n",
       "       [0.        , 0.01566441, 0.01792581],\n",
       "       [0.00493877, 0.01215319, 0.02576911],\n",
       "       [0.        , 0.00661835, 0.02554627],\n",
       "       [0.01857743, 0.01282613, 0.02925842],\n",
       "       [0.0208113 , 0.01213876, 0.03383111],\n",
       "       [0.        , 0.00432354, 0.02644911],\n",
       "       [0.01161136, 0.01094984, 0.02423812],\n",
       "       [0.01360429, 0.01136392, 0.02828777],\n",
       "       [0.01280858, 0.00804281, 0.02407355],\n",
       "       [0.        , 0.01143355, 0.03262212],\n",
       "       [0.00872243, 0.0142118 , 0.03306699],\n",
       "       [0.01825001, 0.01334535, 0.03178166],\n",
       "       [0.01673009, 0.00376882, 0.02967879],\n",
       "       [0.        , 0.01330769, 0.02513198],\n",
       "       [0.00715791, 0.01411042, 0.02382444],\n",
       "       [0.01317643, 0.00784084, 0.02792821],\n",
       "       [0.        , 0.00685088, 0.02494428],\n",
       "       [0.        , 0.01369138, 0.02189571],\n",
       "       [0.01742788, 0.01136782, 0.02978261],\n",
       "       [0.00910236, 0.0115837 , 0.02322455],\n",
       "       [0.01304624, 0.0128918 , 0.02561256],\n",
       "       [0.0177172 , 0.0095371 , 0.02711924],\n",
       "       [0.00413173, 0.01482629, 0.02292213],\n",
       "       [0.01154427, 0.0124442 , 0.03030849],\n",
       "       [0.01899334, 0.        , 0.05445109],\n",
       "       [0.        , 0.        , 0.07612417],\n",
       "       [0.01533236, 0.01351459, 0.03362256],\n",
       "       [0.01697031, 0.01110112, 0.03063553],\n",
       "       [0.        , 0.01531873, 0.07291842],\n",
       "       [0.01475838, 0.0120769 , 0.02483539],\n",
       "       [0.        , 0.02002833, 0.04886316],\n",
       "       [0.        , 0.01281764, 0.01846996],\n",
       "       [0.01132832, 0.00832197, 0.02984183],\n",
       "       [0.        , 0.00698293, 0.02809774],\n",
       "       [0.0212733 , 0.01247208, 0.03197428],\n",
       "       [0.01204773, 0.01534696, 0.03074083],\n",
       "       [0.01290696, 0.01304699, 0.02741756],\n",
       "       [0.01926004, 0.00451291, 0.03255378],\n",
       "       [0.01646701, 0.00617337, 0.02861271],\n",
       "       [0.01562776, 0.01106175, 0.03014268],\n",
       "       [0.02230321, 0.01346683, 0.03149425],\n",
       "       [0.00463568, 0.01409141, 0.01643145],\n",
       "       [0.01228473, 0.01298748, 0.02725143],\n",
       "       [0.01506001, 0.01011726, 0.03584642],\n",
       "       [0.00479752, 0.00956297, 0.02558881],\n",
       "       [0.        , 0.        , 0.10587997],\n",
       "       [0.        , 0.01428382, 0.02805359],\n",
       "       [0.02246653, 0.01596179, 0.03084277],\n",
       "       [0.01255304, 0.01237446, 0.02928685],\n",
       "       [0.0167957 , 0.01191005, 0.02706911],\n",
       "       [0.02356233, 0.01617161, 0.03380425],\n",
       "       [0.        , 0.        , 0.09692596],\n",
       "       [0.02046164, 0.01531062, 0.03362506],\n",
       "       [0.00408166, 0.01240732, 0.02006687],\n",
       "       [0.01413952, 0.01324102, 0.02863094],\n",
       "       [0.02215215, 0.01315728, 0.03155812],\n",
       "       [0.00680586, 0.00568506, 0.0378896 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtm 에서 검색하고자 하는 feature만 뽑아낸다.\n",
    "srch_dtm = np.asarray(X.toarray())[:, [\n",
    "    # vectorize.vocabulary_.get 는 특정 feature 가 dtm 에서 가지고 있는 index값을 리턴한다\n",
    "    vectorize.vocabulary_.get(i) for i in srch\n",
    "]]\n",
    "\n",
    "print(len(srch_dtm))\n",
    "srch_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04013992, 0.04680568, 0.06438658, 0.06104212, 0.03359023,\n",
       "       0.04286107, 0.03216461, 0.06066198, 0.06678117, 0.03077264,\n",
       "       0.04679932, 0.05325599, 0.04492494, 0.04405567, 0.05600122,\n",
       "       0.06337703, 0.0501777 , 0.03843967, 0.04509277, 0.04894548,\n",
       "       0.03179516, 0.03558709, 0.05857831, 0.0439106 , 0.0515506 ,\n",
       "       0.05437354, 0.04188015, 0.05429697, 0.07344442, 0.07612417,\n",
       "       0.0624695 , 0.05870695, 0.08823715, 0.05167066, 0.06889149,\n",
       "       0.0312876 , 0.04949212, 0.03508067, 0.06571965, 0.05813553,\n",
       "       0.0533715 , 0.05632672, 0.0512531 , 0.05683219, 0.06726428,\n",
       "       0.03515854, 0.05252364, 0.06102369, 0.0399493 , 0.10587997,\n",
       "       0.04233741, 0.06927108, 0.05421435, 0.05577485, 0.07353819,\n",
       "       0.09692596, 0.06939733, 0.03655585, 0.05601148, 0.06686755,\n",
       "       0.05038051])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = srch_dtm.sum(axis=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('패들핏', 0.10587996957803501)\n",
      "('필라테스', 0.09692596328676756)\n",
      "('에이리얼후프', 0.08823715393762888)\n",
      "('아쿠아테크', 0.07612417377408401)\n",
      "('플라잉필라테스', 0.07353819008961215)\n",
      "('아쿠아바이크', 0.0734444246412008)\n",
      "('필록싱', 0.06939733047412792)\n",
      "('폴댄스', 0.06927108455991757)\n",
      "('요가쿠아', 0.06889149455714522)\n",
      "('타바타', 0.0672642836739537)\n",
      "('헬스', 0.06686754664399552)\n",
      "('뮤직복싱', 0.06678116705520054)\n",
      "('점핑피트니스', 0.0657196515343316)\n"
     ]
    }
   ],
   "source": [
    "for i in score.argsort()[::-1]:\n",
    "    if score[i] > 0.065:\n",
    "        print((df['exercise_name'].iloc[i], score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
